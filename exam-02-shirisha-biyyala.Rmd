---
title: "Midterm 02"
author: "Shirisha Biyyala"
date: " `r Sys.Date()` "
output: github_document
---

## Load packages and data

```{r load-packages, message = FALSE, warning= FALSE}
library(tidyverse)
library(robotstxt)
library(rvest)
library(scales)
library(stringr)
library(dplyr)
```

```{r bot-check}
library(robotstxt)
paths_allowed("https://www.opensecrets.org")
```

## Exercises

```{r scrape-pac}
# function: scrape_pac ---------------------------------------------------------

scrape_pac <- function(url) {

  # read the page
  page <- read_html(url)

  # extract the table
  # select node .DataTable-Partial (identified using the HTML code)
  pac <- page %>%
    html_node(".DataTable-Partial") %>%
    
    # parse table at node td into a data frame
    # table has a head and empty cells should be filled with NAs
    html_table("td", header = TRUE, trim = TRUE) %>%
    
    # convert to a tibble
    as_tibble()

  # rename variables
  pac <- pac %>%
    
    # rename columns (new name = old name)
    rename(
      name = `PAC Name (Affiliate)` ,
      country_parent = `Country of Origin/Parent Company`,
      total = `Total`,
      dems = `Dems`,
      repubs = `Repubs` 
    )

  # add year
  pac <- pac %>%
    
    # extract last 4 characters of the URL and save as year
    mutate(year = substr(url, nchar(url) - 3, nchar(url)))

  # return data frame
  pac

}

# test function ----------------------------------------------------------------

url_2022 <- "https://www.opensecrets.org/political-action-committees-pacs/foreign-connected-pacs/2022"
pac_2022 <- scrape_pac(url_2022)


url_2020 <- "https://www.opensecrets.org/political-action-committees-pacs/foreign-connected-pacs/2020"
pac_2020 <- scrape_pac(url_2020)

url_2018 <- "https://www.opensecrets.org/political-action-committees-pacs/foreign-connected-pacs/2018"
pac_2018 <- scrape_pac(url_2018)

# list of urls -----------------------------------------------------------------

# first part of url
root <- "https://www.opensecrets.org/political-action-committees-pacs/foreign-connected-pacs/"

# second part of url (election years as a sequence)
year <- seq(from = 2000, to = 2024, by = 2)

# construct urls by pasting first and second parts together
urls <- paste0(root, year)

# map the scrape_pac function over list of urls --------------------------------

pac_all <- map_dfr(urls, scrape_pac)

# write data -------------------------------------------------------------------

# Set the  directory to the exam-02 folder
setwd("C:/Users/shiri/OneDrive/Documents/RStudio/exam-02")

# Write the data to pac-all.csv
write_csv(pac_all, file = "pac-all.csv")
```


#### References:

1. https://www.geeksforgeeks.org/extract-first-or-last-n-characters-from-string-in-r/

### Exercise 1

```{r load-data}
# Load pac-all.csv
pac_all <- read_csv("pac-all.csv")

# Data description
head(pac_all)
glimpse(pac_all)
view(pac_all)

# Report number of observations and variables
n_obs_vars <- str_glue("The dataset has {nrow(pac_all)} observations and {ncol(pac_all)} variables.")
n_obs_vars
```

## Data Cleaning

### Exercise 2

```{r delimeter-cleaning}
# Use separate_wider_delim() to split the country_parent column
pac_all <- pac_all %>%
  separate_wider_delim(country_parent, 
                       delim = "/", 
                       names = c("country", "parent_company"), 
                       too_many = "merge")

# Print the top 10 rows to check the result
head(pac_all, 10)
```


### Exercise 3

```{r remove-spl-char}
# Convert contribution amounts to numeric
pac_all <- pac_all %>%
  mutate(
    total = as.numeric(gsub("[^0-9.-]", "", total)),  # Remove non-numeric characters and convert to numeric
    dems = as.numeric(gsub("[^0-9.-]", "", dems)),    
    repubs = as.numeric(gsub("[^0-9.-]", "", repubs)) 
  )

# Print the top 10 rows to verify the changes
head(pac_all, 10)
```

```{r remove-spl-using-hint, eval=FALSE}
# Clean the columns: remove '$' and ',' then convert to numeric
pac_all <- pac_all %>%
  mutate(
    total = str_remove_all(total, "\\$"),  # Remove dollar sign
    total = str_remove_all(total, ","),    # Remove commas 
    total = as.numeric(total),             # Convert to numeric
    
    dems = str_remove_all(dems, "\\$"),    
    dems = str_remove_all(dems, ","),      
    dems = as.numeric(dems),               
    
    repubs = str_remove_all(repubs, "\\$"),  
    repubs = str_remove_all(repubs, ","),    
    repubs = as.numeric(repubs)             
  )
```


#### References:

1. https://www.geeksforgeeks.org/remove-all-special-characters-from-string-in-r/
2. https://stackoverflow.com/questions/10294284/remove-all-special-characters-from-a-string-in-r

### Exercise 4



### Exercise 5

